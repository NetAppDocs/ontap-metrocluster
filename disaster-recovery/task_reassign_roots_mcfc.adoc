---
permalink: disaster-recovery/task_assign_ownership_mcfc.html
sidebar: sidebar
keywords: configure, fc, switches, metrocluster, configuration
summary: 'After replacing hardware and assigning disks, you can perform the MetroCluster healing operations.'
---
= Performing aggregate healing and restoring mirrors (MetroCluster FC configurations)
:icons: font
:imagesdir: ../media/

[.lead]
After replacing hardware and assigning disks, you can perform the MetroCluster healing operations. You must then confirm that aggregates are mirrored and, if necessary, restart mirroring.

. Perform the two phases of healing (aggregate healing and root healing) on the disaster site:
+
----
cluster_B::> metrocluster heal -phase aggregates

cluster_B::> metrocluster heal -phase root aggregates
----

. Monitor the healing and verify that the aggregates are in either the resyncing or mirrored state: `storage aggregate show -node local`
+
|===
| If the aggregate shows this state...| Then...
a|
resyncing
a|
No action is required.    Let the aggregate complete resyncing.
a|
mirror degraded
a|
Proceed to step xref:task_prepare_for_switchback_in_a_mcc_fc_configuration_supertask.adocSTEP_0192B6F128114A77837D1BB5AAB8A770[3].
a|
mirrored, normal
a|
No action is required.
a|
unknown, offline
a|
The root aggregate shows this state if all the disks on the disaster sites were replaced.
|===
+
----
cluster_B::> storage aggregate show -node local

 Aggregate     Size Available Used% State   #Vols  Nodes      RAID Status
 --------- -------- --------- ----- ------- ------ ---------- ------------
 node_B_1_aggr1
            227.1GB   11.00GB   95% online       1 node_B_1   raid_dp,
                                                              resyncing
 NodeA_1_aggr2
            430.3GB   28.02GB   93% online       2 node_B_1   raid_dp,
                                                              mirror
                                                              degraded
 node_B_1_aggr3
            812.8GB   85.37GB   89% online       5 node_B_1   raid_dp,
                                                              mirrored,
                                                              normal
 3 entries were displayed.

cluster_B::>
----
+
In the following examples, the three aggregates are each in a different state:
+
|===
| Node| State
a|
node_B_1_aggr1
a|
resyncing
a|
node_B_1_aggr2
a|
mirror degraded
a|
node_B_1_aggr3
a|
mirrored, normal
|===

. If one or more plexes remain offline, additional steps are required to rebuild the mirror.
+
In the preceding table, the mirror for node_B_1_aggr2 must be rebuilt.

 .. View details of the aggregate to identify any failed plexes: `storage aggregate show -r -aggregate node_B_1_aggr2`
+
In the following example, plex /node_B_1_aggr2/plex0 is in a failed state:
+
----
cluster_B::> storage aggregate show -r -aggregate node_B_1_aggr2

 Owner Node: node_B_1
  Aggregate: node_B_1_aggr2 (online, raid_dp, mirror degraded) (block checksums)
   Plex: /node_B_1_aggr2/plex0 (offline, failed, inactive, pool0)
    RAID Group /node_B_1_aggr2/plex0/rg0 (partial)
                                                               Usable Physical
      Position Disk                     Pool Type     RPM     Size     Size Status
      -------- ------------------------ ---- ----- ------ -------- -------- ----------

   Plex: /node_B_1_aggr2/plex1 (online, normal, active, pool1)
    RAID Group /node_B_1_aggr2/plex1/rg0 (normal, block checksums)
                                                               Usable Physical
      Position Disk                     Pool Type     RPM     Size     Size Status
      -------- ------------------------ ---- ----- ------ -------- -------- ----------
      dparity  1.44.8                    1   SAS    15000  265.6GB  273.5GB (normal)
      parity   1.41.11                   1   SAS    15000  265.6GB  273.5GB (normal)
      data     1.42.8                    1   SAS    15000  265.6GB  273.5GB (normal)
      data     1.43.11                   1   SAS    15000  265.6GB  273.5GB (normal)
      data     1.44.9                    1   SAS    15000  265.6GB  273.5GB (normal)
      data     1.43.18                   1   SAS    15000  265.6GB  273.5GB (normal)
 6 entries were displayed.

 cluster_B::>
----

 .. Delete the failed plex: `storage aggregate plex delete -aggregate aggregate-name -plex plex`
 .. Reestablish the mirror: `storage aggregate mirror -aggregate aggregate-name`
 .. Monitor the resynchronization and mirroring status of the plex until all mirrors are reestablished and all aggregates show mirrored, normal status: `storage aggregate show`

== Reassigning disk ownership for root aggregates to replacement controller modules (MetroCluster FC configurations)

[.lead]
If one or both of the controller modules or NVRAM cards were replaced at the disaster site, the system ID has changed and you must reassign disks belonging to the root aggregates to the replacement controller modules.

Because the nodes are in switchover mode and healing has been done, only the disks containing the root aggregates of pool1 of the disaster site will be reassigned in this section. They are the only disks still owned by the old system ID at this point.

This section provides examples for two and four-node configurations. For two-node configurations, you can ignore references to the second node at each site. For eight-node configurations, you must account for the additional nodes on the second DR group. The examples make the following assumptions:

* Site A is the disaster site.
* node_A_1 has been replaced.
* node_A_2 has been replaced.
+
Present only in four-node MetroCluster configurations.

* Site B is the surviving site.
* node_B_1 is healthy.
* node_B_2 is healthy.
+
Present only in four-node MetroCluster configurations.

The old and new system IDs were identified in xref:task_replace_hardware_and_boot_new_controllers.adoc[Acquiring the new System ID].

The examples in this procedure use controllers with the following system IDs:

|===
| Number of nodes| Node| Original system ID| New system ID
a|
Four
a|
node_A_1
a|
4068741258
a|
1574774970
a|
node_A_2
a|
4068741260
a|
1574774991
a|
node_B_1
a|
4068741254
a|
unchanged
a|
node_B_2
a|
4068741256
a|
unchanged
a|
Two
a|
node_A_1
a|
4068741258
a|
1574774970
a|
node_B_1
a|
4068741254
a|
unchanged
|===

. With the replacement node in Maintenance mode, reassign the root aggregate disks: `disk reassign -s old-system-ID -d new-system-ID`
+
----
*> disk reassign -s 4068741258 -d 1574774970
----

. View the disks to confirm the ownership change of the pool1 root aggr disks of the disaster site to the replacement node: `disk show`
+
The output might show more or fewer disks, depending on how many disks are in the root aggregate and whether any of these disks failed and were replaced. If the disks were replaced, then Pool0 disks will not appear in the output.
+
The pool1 root aggregate disks of the disaster site should now be assigned to the replacement node.
+
----
*> disk show
Local System ID: 1574774970

  DISK             OWNER             POOL   SERIAL NUMBER         HOME                DR HOME
------------       -------------     -----  -------------         -------------       -------------
sw_A_1:6.126L19 node_A_1(1574774970) Pool0  serial-number  node_A_1(1574774970)
sw_A_1:6.126L3  node_A_1(1574774970) Pool0  serial-number  node_A_1(1574774970)
sw_A_1:6.126L7  node_A_1(1574774970) Pool0  serial-number  node_A_1(1574774970)
sw_B_1:6.126L8  node_A_1(1574774970) Pool1  serial-number  node_A_1(1574774970)
sw_B_1:6.126L24 node_A_1(1574774970) Pool1  serial-number  node_A_1(1574774970)
sw_B_1:6.126L2  node_A_1(1574774970) Pool1  serial-number  node_A_1(1574774970)

*> aggr status
         Aggr State           Status
 node_A_1_root online          raid_dp, aggr
                               mirror degraded
                               64-bit
*>
----

. View the aggregate status: `aggr status`
+
The output might show more or fewer disks, depending on how many disks are in the root aggregate and whether any of these disks failed and were replaced. If disks were replaced, then Pool0 disks will not appear in output.
+
----
*> aggr status
          Aggr State           Status
  node_A_1_root online          raid_dp, aggr
                                mirror degraded
                                64-bit
*>
----

. Delete the contents of the mailbox disks: `mailbox destroy local`
. If the aggregate is not online, bring it online: `aggr online aggr_name`
. Halt the node to display the LOADER prompt: `halt`

== Booting the new controller modules (MetroCluster FC configurations)

[.lead]
After aggregate healing has been completed for both the data and root aggregates, you must boot the node or nodes at the disaster site.

This task begins with the nodes showing the LOADER prompt.

. Display the boot menu: `boot_ontap menu`
. From the boot menu, select option 6, *Update flash from backup config*.
. Respond y to the following prompt:This will replace all flash-based configuration with the last backup to disks. Are you sure you want to continue?: y
+
The system will boot twice, the second time to load the new configuration.
+
NOTE: If you did not clear the NVRAM contents of a used replacement controller, then you might see a panic with the following message: PANIC: NVRAM contents are invalid...
+
If this occurs, repeat step 2 to boot the system to the ONTAP prompt. You will then need to perform a root recovery. Contact technical support for assistance.

. Mirror the root aggregate on plex 0:
 .. Assign three pool0 disks to the new controller module.
 .. Mirror the root aggregate pool1 plex: `aggr mirror root-aggr-name`
 .. Assign unowned disks to pool0 on the local node
. Refresh the MetroCluster configuration:
 .. Enter advanced privilege mode: `set -privilege advanced`
 .. Refresh the configuration: `metrocluster configure -refresh true`
 .. Return to admin privilege mode: `set -privilege admin`
. If you have a four-node configuration, repeat the previous steps on the other node at the disaster site.

Proceed to verify the licenses on the replaced nodes.

link:../disaster-recovery/task_complete_recovery.adoc[Verifying licenses on the replaced nodes]
