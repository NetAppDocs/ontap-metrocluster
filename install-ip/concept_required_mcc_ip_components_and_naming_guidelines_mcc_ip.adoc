---
permalink: install-ip/concept_required_mcc_ip_components_and_naming_guidelines_mcc_ip.html
sidebar: sidebar
keywords: plan, metrocluster, ip, configuration, planning, require, hardware, software, clarity, conventions, component, documentation, naming, name, requirement, support, redundancy, switch, ontap, cluster, controller, module, gigabit, ethernet, adapter, pool, drive, drive, location, consideration, partial, populate, shelves, shelf, aff, a800, internal, iom12, iom, module, stack, four-node, raid-dp, raid4, AFF A800 internal drives
summary: When planning your MetroCluster IP configuration, you must understand the required and supported hardware and software components. For convenience and clarity, you should also understand the naming conventions used for components in examples throughout the documentation.
---
= Required MetroCluster IP components and naming conventions
:icons: font
:imagesdir: ../media/

[.lead]
When planning your MetroCluster IP configuration, you must understand the required and supported hardware and software components. For convenience and clarity, you should also understand the naming conventions used for components in examples throughout the documentation.

== Supported software and hardware

The hardware and software must be supported for the MetroCluster IP configuration.

https://hwu.netapp.com[NetApp Hardware Universe]

When using AFF systems, all controller modules in the MetroCluster configuration must be configured as AFF systems.

== Hardware redundancy requirements in a MetroCluster IP configuration

Because of the hardware redundancy in the MetroCluster IP configuration, there are two of each component at each site. The sites are arbitrarily assigned the letters A and B, and the individual components are arbitrarily assigned the numbers 1 and 2.

== ONTAP cluster requirements in a MetroCluster IP configuration

MetroCluster IP configurations require two ONTAP clusters, one at each MetroCluster site.

Naming must be unique within the MetroCluster configuration.

Example names:

* Site A: cluster_A
* Site B: cluster_B

== IP switch requirements in a MetroCluster IP configuration

MetroCluster IP configurations require four IP switches. The four switches form two switch storage fabrics that provide the ISL between each of the clusters in the MetroCluster IP configuration.

The IP switches also provide intracluster communication among the controller modules in each cluster.

Naming must be unique within the MetroCluster configuration.

Example names:

* Site A: cluster_A
 ** IP_switch_A_1
 ** IP_switch_A_2
* Site B: cluster_B
 ** IP_switch_B_1
 ** IP_switch_B_2

== Controller module requirements in a MetroCluster IP configuration

MetroCluster IP configurations require four or eight controller modules.

The controller modules at each site form an HA pair. Each controller module has a DR partner at the other site.

Each controller module must be running the same ONTAP version. Supported platform models depend on the ONTAP version:

* New MetroCluster IP installations on FAS systems are not supported in ONTAP 9.4.
+
Existing MetroCluster IP configurations on FAS systems can be upgraded to ONTAP 9.4.

* Beginning with ONTAP 9.5, new MetroCluster IP installations on FAS systems are supported.
* Beginning with ONTAP 9.4, controller modules configured for ADP are supported.

=== Controller models limited to four-node configurations

These models are limited to four in a MetroCluster configuration.

* AFF A220
* AFF A250
* FAS2750
* FAS500f

For example, the following configurations are not supported:

* An eight-node configuration consisting of eight AFF A250 controllers.
* An eight-node configuration consisting of four AFF 220 controllers and four FAS500f controllers.
* Two four-node MetroCluster IP configurations each consisting of AFF A250 controllers and sharing the same back-end switches.
* An eight-node configuration consisting of DR Group 1 with AFF A250 controllers and DR Group 2 with FAS9000 controllers.

You can configure two separate four-node MetroCluster IP configurations with the same back-end switches if the second MetroCluster does not include any of the above models.

=== Example names

The following example names are used in the documentation:

* Site A: cluster_A
 ** controller_A_1
 ** controller_A_2
* Site B: cluster_B
 ** controller_B_1
 ** controller_B_2

== Gigabit Ethernet adapter requirements in a MetroCluster IP configuration

MetroCluster IP configurations use a 40/100 Gbps or 10/25 Gbps Ethernet adapter for the IP interfaces to the IP switches used for the MetroCluster IP fabric.

|===

h| Platform model h| Required Gigabit Ethernet adapter h| Required slot for adapter h| Ports

| AFF A900 | X91146A | Slot 5, Slot 7 | e5b, e7b
a|
AFF A700 and FAS9000
a|
X91146A-C
a|
Slot 5
a|
e5a, e5b
a|
AFF A800
a|
X1146A/onboard ports
a|
Slot 1
a|
e0b. e1b
a|
AFF A400 and FAS8300
a|
X1146A
a|
Slot 1
a|
e1a, e1b
//ontap-metrocluster/issues/79
a|
AFF A300 and FAS8200
a|
X1116A
a|
Slot 1
a|
e1a, e1b
a|
AFF A220, and FAS2750
a|
Onboard ports
a|
Slot 0
a|
e0a, e0b
a|
AFF A250 and FAS500f
a|
Onboard ports
a|
Slot 0
a|
e0c, e0d
a|
AFF A320
a|
Onboard ports
a|
Slot 0
a|
e0g, e0h
|===

== Pool and drive requirements (minimum supported)

Eight SAS disk shelves are recommended (four shelves at each site) to allow disk ownership on a per-shelf basis.

A four-node MetroCluster IP configuration requires the minimum configuration at each site:

* Each node has at least one local pool and one remote pool at the site.
* At least seven drives in each pool.
+
In a four-node MetroCluster configuration with a single mirrored data aggregate per node, the minimum configuration requires 24 disks at the site.

In a minimum supported configuration, each pool has the following drive layout:

* Three root drives
* Three data drives
* One spare drive

In a minimum supported configuration, at least one shelf is needed per site.

MetroCluster configurations support RAID-DP and RAID4.

== Drive location considerations for partially populated shelves

For correct auto-assignment of drives when using shelves that are half populated (12 drives in a 24-drive shelf), drives should be located in slots 0-5 and 18-23.

In a configuration with a partially populated shelf, the drives must be evenly distributed in the four quadrants of the shelf.

== Drive location considerations for AFF A800 internal drives

For correct implementation of the ADP feature, the AFF A800 system disk slots must be divided into quarters and the disks must be located symmetrically in the quarters.

An AFF A800 system has 48 drive bays. The bays can be divided into quarters:

* Quarter one:
 ** Bays 0 - 5
 ** Bays 24 - 29
* Quarter two:
 ** Bays 6 - 11
 ** Bays 30 - 35
* Quarter three:
 ** Bays 12 - 17
 ** Bays 36 - 41
* Quarter four:
 ** Bays 18 - 23
 ** Bays 42 - 47

If this system is populated with 16 drives, they must be symmetrically distributed among the four quarters:

* Four drives in the first quarter: 0, 1, 2, 3
* Four drives in the second quarter: 6, 7, 8, 9
* Four drives in the third quarter: 12, 13, 14, 15
* Four drives in the fourth quarter: 18, 19, 20, 21

== Mixing IOM12 and IOM 6 modules in a stack

Your version of ONTAP must support shelf mixing. Refer to the https://mysupport.netapp.com/NOW/products/interoperability[NetApp Interoperability Matrix Tool (IMT)] to see if your version of ONTAP supports shelf mixing.

For further details on shelf mixing, see https://docs.netapp.com/platstor/topic/com.netapp.doc.hw-ds-mix-hotadd/home.html[Hot-adding shelves with IOM12 modules to a stack of shelves with IOM6 modules]
// 2021-04-21 1374268
// 2022-01-10, Issue 120
